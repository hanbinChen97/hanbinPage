# Select the LLM provider: "openai", "azure", "huggingface"
LLM_PROVIDER="openai"

# OpenAI Configuration
OPENAI_API_KEY="sk-..." # Your OpenAI API Key

# Azure OpenAI Configuration (only needed if LLM_PROVIDER="azure")
AZURE_OPENAI_API_KEY="..."
AZURE_OPENAI_ENDPOINT="..." # e.g., https://your-resource-name.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME="..." # The 'Deployment name' of your model in Azure AI Studio

# Hugging Face Configuration (only needed if LLM_PROVIDER="huggingface")
# For models compatible with the Vercel AI SDK (e.g., via Inference Endpoints or TGI)
HF_API_KEY="hf_..." # Your Hugging Face API Key (if required by the endpoint)
HF_MODEL_ENDPOINT="https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct" # Example: Llama 3 8B Instruct. Replace with your desired model endpoint.
HF_MODEL_ID="meta-llama/Meta-Llama-3-8B-Instruct" # Optional: Model ID, if needed by the endpoint or for clarity. Can often be derived from endpoint.
